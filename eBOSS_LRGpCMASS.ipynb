{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b7425e",
   "metadata": {},
   "source": [
    "## Hands on real clustering data - eBOSS LRG (plus BOSS CMASS) sample\n",
    "In this session we will compute the correlation function / power spectrum of the input galaxy catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd0667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astropy.table import Table\n",
    "\n",
    "import environment\n",
    "from environment import Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735d0a2",
   "metadata": {},
   "source": [
    "Download eBOSS LRGpCMASS catalogs here: https://drive.google.com/drive/folders/182f-FSa0uWgovIxVNdpp0pFYWOVc3jc7?usp=sharing  \n",
    "(These are a \"light version\" of the official catalogs provided at https://data.sdss.org/sas/dr16/eboss/lss/catalogs/DR16/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25c0c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = 'LRGpCMASS'\n",
    "cap = 'NGC'\n",
    "recon = False\n",
    "path_data, path_randoms = environment.path_catalogs(tracer=tracer,cap=cap,recon=recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f471a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TableColumns names=('RA','DEC','Z','WEIGHT_SYSTOT','WEIGHT_CP','WEIGHT_NOZ','NZ')>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Table.read(path_data)\n",
    "randoms = Table.read(path_randoms)\n",
    "data.columns\n",
    "randoms.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c84aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a scatter plot of RA/Dec, histogram of NZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6790359",
   "metadata": {},
   "source": [
    "We will transform input angular coordinates RA/Dec and redshifts Z into cartesian positions, assuming a fiducial cosmology. You can e.g. take BOSS and eBOSS fiducial cosmology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfd49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbodykit.lab import cosmology\n",
    "\n",
    "def get_cosmo_BOSS():\n",
    "    # BOSS and eBOSS fiducial cosmologies\n",
    "    cosmo_kwargs = dict(Omega_m=0.31,omega_b=0.022,h=0.676,sigma8=0.8,n_s=0.97,N_ur=2.0328,m_ncdm=[0.06])\n",
    "    cosmo_kwargs['Omega0_b'] = cosmo_kwargs.pop('omega_b')/cosmo_kwargs['h']**2\n",
    "    Omega0_m = cosmo_kwargs.pop('Omega_m')\n",
    "    sigma8 = cosmo_kwargs.pop('sigma8')\n",
    "    cosmo = cosmology.Cosmology(**cosmo_kwargs).match(Omega0_m=Omega0_m).match(sigma8=sigma8)\n",
    "    return cosmo\n",
    "\n",
    "cosmo_fid = get_cosmo_BOSS()\n",
    "data['DISTANCE'] = cosmo_fid.comoving_distance(data['Z'])\n",
    "# same for random catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166eaf32",
   "metadata": {},
   "source": [
    "Galaxies (and randoms) in the catalog receive weights, to correct for systematic effects\n",
    "(such that the ensemble average of galaxy density matches that of randoms):\n",
    "- WEIGHT_SYSTOT: weights to correct for photometric systematics: what are they?  \n",
    "- WEIGHT_CP: weights to correct for fiber collisions: what are they?  \n",
    "- WEIGHT_NOZ: weights to correct for redshift failures: what are they?\n",
    "\n",
    "The total (completenes) weight is: WEIGHT_COMP = WEIGHT_SYSTOT * WEIGHT_CP * WEIGHT_NOZ.  \n",
    "    In addition, you can apply weights to minimize variance: WEIGHT_FKP = 1/(1 + NZ * P0), with P0 the typical value of the power spectrum at the scales of interest, e.g. $10000 \\; (\\mathrm{Mpc}/h)^{3}$ (NZ is in $(\\mathrm{Mpc}/h)^{3}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8e257e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['WEIGHT'] = data['WEIGHT_COMP'] * data['WEIGHT_FKP']\n",
    "# same for randoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d76792",
   "metadata": {},
   "source": [
    "### Now compute pair counts as a function of (s,mu)\n",
    "If you are running out of time, you can directly use https://nbodykit.readthedocs.io/en/latest/api/_autosummary/nbodykit.algorithms.paircount_tpcf.tpcf.html#nbodykit.algorithms.paircount_tpcf.tpcf.SurveyData2PCF  \n",
    "Otherwise, it is more instructive to start from Corrfunc https://corrfunc.readthedocs.io/en/master/api/Corrfunc.mocks.html#Corrfunc.mocks.DDsmu_mocks   \n",
    "which you will use to compute data - data pairs (DD), data - random pairs (DR), random - random pairs (RR).  \n",
    "Then, use the Landy-Szalay estimator to compute the correlation function: $\\xi(s,\\mu) = \\frac{DD(s,\\mu) - 2DR(s,\\mu) + RR(s,\\mu)}{RR(s,\\mu)}$.  \n",
    "Note that you should normalize each pair count by the total weighted number of pairs in the survey. What is it?  \n",
    "(An example of implementation of the Landy-Szalay estimator can be found in correlation_function.py and a use case in estimators.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76aafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. to cross-correlate catalogs cat1 and cat2\n",
    "# import Corrfunc\n",
    "# Corrfunc.mocks.DDsmu_mocks(False,cosmology=1,nthreads=4,mu_max=1.,nmu_bins=100,binfile=sedges,\n",
    "#                            RA1=cat1['RA'],DEC1=cat1['DEC'],CZ1=cat1['DISTANCE'],weights1=cat1['WEIGHT'],\n",
    "#                            RA2=cat2['RA'],DEC2=cat2['DEC'],CZ2=cat2['DISTANCE'],weights2=cat2['WEIGHT'],\n",
    "#                            is_comoving_dist=True,verbose=True,output_savg=False,weight_type='pair_product')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c844529",
   "metadata": {},
   "source": [
    "### Compute multipoles of the correlation function\n",
    "Multipoles are given by $\\xi_{\\ell}(s) = \\frac{2 \\ell + 1}{2} \\int_{-1}^{1} d\\mu \\xi(s,\\mu) \\mathcal{L}(\\mu)$,\n",
    "with $\\mathcal{L}(\\mu)$ Legendre polynomials (see https://en.wikipedia.org/wiki/Legendre_polynomials, also https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.legendre.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8605db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation function multipoles!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae03bc",
   "metadata": {},
   "source": [
    "### Estimate power spectrum multipoles\n",
    "https://nbodykit.readthedocs.io/en/latest/api/_autosummary/nbodykit.algorithms.convpower.fkp.html\n",
    "https://nbodykit.readthedocs.io/en/0.1.11/algorithms/survey-power.html   \n",
    "Weighted data and randoms are interpolated onto a mesh.   \n",
    "The Fourier-space field is computed using Fast Fourier Transforms (FFTs).   \n",
    "Note that such sampling of the galaxy density field yields to artefacts that must be corrected:\n",
    "smoothing (due to interpolation on the mesh) and aliasing (high frequencies entering into low frequency modes).\n",
    "How are they corrected for? (already included in nbodykit's ConvolvedFFTPower).  \n",
    "A Poisson shot noise term is usually subtracted from the monopole. Why?  \n",
    "(An example of running power spectrum estimation can be found in estimators.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365a2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbodykit.lab import FITSCatalog, FKPCatalog, ConvolvedFFTPower\n",
    "# data = FITSCatalog(data)\n",
    "# randoms = FITSCatalog(randoms)\n",
    "# fill in WEIGHT_COMP, WEIGHT_FKP\n",
    "# fkp = FKPCatalog(data,randoms)\n",
    "# BoxSize = 3000.\n",
    "# Nmesh = 100 # increase if you have more memory on your computer\n",
    "# mesh = fkp.to_mesh(position='POSITION',fkp_weight='WEIGHT_FKP',comp_weight='WEIGHT_COMP',nbar='NZ',BoxSize=BoxSize,Nmesh=Nmesh,resampler='tsc',interlaced=True,compensated=True)\n",
    "# power = ConvolvedFFTPower(mesh,poles=(0,2,4),kmin=0.,dk=0.01)\n",
    "# print(power.poles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5973ea6",
   "metadata": {},
   "source": [
    "### Bonus, cosmological constraints with BAO!\n",
    "Follow instructions in bao_inverse_distance_ladder.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmopipe-dev",
   "language": "python",
   "name": "cosmopipe-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
